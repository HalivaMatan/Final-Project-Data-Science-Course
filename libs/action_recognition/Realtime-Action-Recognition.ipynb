{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[2021-02-23 20:21:40,147] [TfPoseEstimator] [INFO] loading graph from C:\\Users\\Haliva\\Data Science\\Realtime-Action-Recognition-master\\models\\graph/mobilenet_thin/graph_opt.pb(default size=656x368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Haliva\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:44,280] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:44,280] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 0th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:45,108] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:45,108] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:45,129] [TfPoseEstimator] [DEBUG] estimate time=0.01895\n",
      "[2021-02-23 20:21:45,129] [TfPoseEstimator] [DEBUG] estimate time=0.01895\n",
      "[2021-02-23 20:21:45,135] [TfPoseEstimator] [INFO] inference image in 0.8549 seconds.\n",
      "[2021-02-23 20:21:45,135] [TfPoseEstimator] [INFO] inference image in 0.8549 seconds.\n",
      "[2021-02-23 20:21:45,300] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:45,300] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{1: '', 2: '', 3: '', 4: '', 5: ''}\n",
      "\n",
      "Processing 1th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:46,034] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:46,034] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:46,048] [TfPoseEstimator] [DEBUG] estimate time=0.01117\n",
      "[2021-02-23 20:21:46,048] [TfPoseEstimator] [DEBUG] estimate time=0.01117\n",
      "[2021-02-23 20:21:46,051] [TfPoseEstimator] [INFO] inference image in 0.7511 seconds.\n",
      "[2021-02-23 20:21:46,051] [TfPoseEstimator] [INFO] inference image in 0.7511 seconds.\n",
      "[2021-02-23 20:21:46,201] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:46,201] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{3: '', 4: '', 5: '', 6: '', 7: ''}\n",
      "\n",
      "Processing 2th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:46,860] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:46,860] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:46,870] [TfPoseEstimator] [DEBUG] estimate time=0.00855\n",
      "[2021-02-23 20:21:46,870] [TfPoseEstimator] [DEBUG] estimate time=0.00855\n",
      "[2021-02-23 20:21:46,874] [TfPoseEstimator] [INFO] inference image in 0.6734 seconds.\n",
      "[2021-02-23 20:21:46,874] [TfPoseEstimator] [INFO] inference image in 0.6734 seconds.\n",
      "[2021-02-23 20:21:46,981] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:46,981] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{4: '', 5: '', 7: '', 8: '', 9: ''}\n",
      "\n",
      "Processing 3th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:47,670] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:47,670] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:47,681] [TfPoseEstimator] [DEBUG] estimate time=0.00898\n",
      "[2021-02-23 20:21:47,681] [TfPoseEstimator] [DEBUG] estimate time=0.00898\n",
      "[2021-02-23 20:21:47,685] [TfPoseEstimator] [INFO] inference image in 0.7027 seconds.\n",
      "[2021-02-23 20:21:47,685] [TfPoseEstimator] [INFO] inference image in 0.7027 seconds.\n",
      "[2021-02-23 20:21:47,792] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:47,792] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{4: '', 5: '', 7: '', 9: '', 10: ''}\n",
      "\n",
      "Processing 4th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:48,429] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:48,429] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:48,449] [TfPoseEstimator] [DEBUG] estimate time=0.01796\n",
      "[2021-02-23 20:21:48,449] [TfPoseEstimator] [DEBUG] estimate time=0.01796\n",
      "[2021-02-23 20:21:48,456] [TfPoseEstimator] [INFO] inference image in 0.6642 seconds.\n",
      "[2021-02-23 20:21:48,456] [TfPoseEstimator] [INFO] inference image in 0.6642 seconds.\n",
      "[2021-02-23 20:21:48,566] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:48,566] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [6.38022648e-196 2.30484965e-053 8.59886567e-024 9.98772642e-001\n",
      " 1.34394643e-073 1.30179910e-038 1.22735775e-003 2.32557419e-052\n",
      " 5.78536059e-074]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [5.31377664e-275 4.85469406e-101 1.00000000e+000 1.75703169e-013\n",
      " 4.65142381e-103 3.64812391e-030 2.32076299e-045 2.81277327e-073\n",
      " 2.57451144e-125]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : jump\n",
      "dict_id2label\n",
      "{4: 'jump', 5: 'run', 10: '', 11: '', 12: ''}\n",
      "\n",
      "Processing 5th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:49,179] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:49,179] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:49,195] [TfPoseEstimator] [DEBUG] estimate time=0.01464\n",
      "[2021-02-23 20:21:49,195] [TfPoseEstimator] [DEBUG] estimate time=0.01464\n",
      "[2021-02-23 20:21:49,198] [TfPoseEstimator] [INFO] inference image in 0.6327 seconds.\n",
      "[2021-02-23 20:21:49,198] [TfPoseEstimator] [INFO] inference image in 0.6327 seconds.\n",
      "[2021-02-23 20:21:49,306] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:49,306] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [3.19011324e-196 1.15242482e-053 4.29943283e-024 9.99386321e-001\n",
      " 6.71973214e-074 6.50899550e-039 6.13678877e-004 1.16278709e-052\n",
      " 2.89268029e-074]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [2.65688832e-275 2.42734703e-101 5.00000000e-001 5.00000000e-001\n",
      " 2.32571191e-103 1.82406196e-030 1.16038149e-045 1.40638664e-073\n",
      " 2.55661562e-105]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : jump\n",
      "dict_id2label\n",
      "{4: 'jump', 5: 'jump', 12: '', 13: '', 14: ''}\n",
      "\n",
      "Processing 6th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:49,911] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:49,911] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:49,925] [TfPoseEstimator] [DEBUG] estimate time=0.01198\n",
      "[2021-02-23 20:21:49,925] [TfPoseEstimator] [DEBUG] estimate time=0.01198\n",
      "[2021-02-23 20:21:49,930] [TfPoseEstimator] [INFO] inference image in 0.6239 seconds.\n",
      "[2021-02-23 20:21:49,930] [TfPoseEstimator] [INFO] inference image in 0.6239 seconds.\n",
      "[2021-02-23 20:21:50,031] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:50,031] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [2.16888582e-283 4.87350800e-079 4.99999998e-001 5.00000000e-001\n",
      " 1.34625721e-096 1.57497757e-030 1.89518619e-009 5.84180605e-111\n",
      " 2.55661562e-105]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : jump\n",
      "dict_id2label\n",
      "{5: 'jump', 12: '', 14: '', 15: '', 16: ''}\n",
      "\n",
      "Processing 7th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:50,597] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:50,597] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:50,607] [TfPoseEstimator] [DEBUG] estimate time=0.00799\n",
      "[2021-02-23 20:21:50,607] [TfPoseEstimator] [DEBUG] estimate time=0.00799\n",
      "[2021-02-23 20:21:50,613] [TfPoseEstimator] [INFO] inference image in 0.5824 seconds.\n",
      "[2021-02-23 20:21:50,613] [TfPoseEstimator] [INFO] inference image in 0.5824 seconds.\n",
      "[2021-02-23 20:21:50,708] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:50,708] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [3.20216897e-63 4.99985700e-01 4.99999998e-01 7.10879443e-14\n",
      " 5.89107770e-43 1.57497846e-30 1.43022312e-05 5.79180582e-23\n",
      " 3.00187860e-27]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{5: '', 12: '', 16: '', 17: '', 18: ''}\n",
      "\n",
      "Processing 8th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:51,306] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:51,306] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:51,320] [TfPoseEstimator] [DEBUG] estimate time=0.01203\n",
      "[2021-02-23 20:21:51,320] [TfPoseEstimator] [DEBUG] estimate time=0.01203\n",
      "[2021-02-23 20:21:51,326] [TfPoseEstimator] [INFO] inference image in 0.6170 seconds.\n",
      "[2021-02-23 20:21:51,326] [TfPoseEstimator] [INFO] inference image in 0.6170 seconds.\n",
      "[2021-02-23 20:21:51,432] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:51,432] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [3.20216897e-63 4.99985700e-01 4.97353821e-01 1.08300869e-03\n",
      " 5.01895929e-26 1.20725536e-11 1.57747016e-03 7.25678338e-22\n",
      " 3.00187860e-27]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [7.95112203e-54 7.30122025e-10 9.87635226e-09 2.72660398e-15\n",
      " 5.27550803e-30 1.30465679e-25 9.99999989e-01 2.96608580e-26\n",
      " 4.82724697e-15]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{5: '', 12: 'kick', 18: '', 19: '', 20: ''}\n",
      "\n",
      "Processing 9th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:52,039] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:52,039] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:52,055] [TfPoseEstimator] [DEBUG] estimate time=0.01401\n",
      "[2021-02-23 20:21:52,055] [TfPoseEstimator] [DEBUG] estimate time=0.01401\n",
      "[2021-02-23 20:21:52,058] [TfPoseEstimator] [INFO] inference image in 0.6264 seconds.\n",
      "[2021-02-23 20:21:52,058] [TfPoseEstimator] [INFO] inference image in 0.6264 seconds.\n",
      "[2021-02-23 20:21:52,144] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:52,144] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [3.25242846e-79 5.52909008e-16 4.97353821e-01 1.08300869e-03\n",
      " 5.01895929e-26 1.20725536e-11 5.01563170e-01 6.67760280e-22\n",
      " 1.76892418e-30]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : kick\n",
      "dict_id2label\n",
      "{5: 'kick', 18: '', 20: '', 21: '', 22: ''}\n",
      "\n",
      "Processing 10th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:52,716] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:52,716] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:52,726] [TfPoseEstimator] [DEBUG] estimate time=0.00898\n",
      "[2021-02-23 20:21:52,726] [TfPoseEstimator] [DEBUG] estimate time=0.00898\n",
      "[2021-02-23 20:21:52,731] [TfPoseEstimator] [INFO] inference image in 0.5876 seconds.\n",
      "[2021-02-23 20:21:52,731] [TfPoseEstimator] [INFO] inference image in 0.5876 seconds.\n",
      "[2021-02-23 20:21:52,800] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:52,800] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [7.23913230e-54 1.93492685e-10 1.39993769e-08 1.49901391e-01\n",
      " 9.66500309e-24 9.64758765e-19 8.50098595e-01 7.55960880e-17\n",
      " 8.37237542e-16]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : kick\n",
      "dict_id2label\n",
      "{5: 'kick', 20: '', 22: '', 23: '', 24: ''}\n",
      "\n",
      "Processing 11th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:53,386] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:53,386] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:53,399] [TfPoseEstimator] [DEBUG] estimate time=0.01098\n",
      "[2021-02-23 20:21:53,399] [TfPoseEstimator] [DEBUG] estimate time=0.01098\n",
      "[2021-02-23 20:21:53,406] [TfPoseEstimator] [INFO] inference image in 0.6059 seconds.\n",
      "[2021-02-23 20:21:53,406] [TfPoseEstimator] [INFO] inference image in 0.6059 seconds.\n",
      "[2021-02-23 20:21:53,507] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:53,507] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{20: '', 22: '', 24: '', 25: '', 26: ''}\n",
      "\n",
      "Processing 12th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:54,122] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:54,122] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:54,132] [TfPoseEstimator] [DEBUG] estimate time=0.00897\n",
      "[2021-02-23 20:21:54,132] [TfPoseEstimator] [DEBUG] estimate time=0.00897\n",
      "[2021-02-23 20:21:54,135] [TfPoseEstimator] [INFO] inference image in 0.6284 seconds.\n",
      "[2021-02-23 20:21:54,135] [TfPoseEstimator] [INFO] inference image in 0.6284 seconds.\n",
      "[2021-02-23 20:21:54,237] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:54,237] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [2.30263100e-105 5.46802413e-062 1.00000000e+000 3.42622869e-034\n",
      " 1.88813310e-038 1.03660322e-016 6.47557520e-016 3.42603413e-057\n",
      " 6.93623965e-039]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : run\n",
      "dict_id2label\n",
      "{20: 'run', 25: '', 26: '', 27: '', 28: ''}\n",
      "\n",
      "Processing 13th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:54,850] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:54,850] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:54,860] [TfPoseEstimator] [DEBUG] estimate time=0.00798\n",
      "[2021-02-23 20:21:54,860] [TfPoseEstimator] [DEBUG] estimate time=0.00798\n",
      "[2021-02-23 20:21:54,867] [TfPoseEstimator] [INFO] inference image in 0.6306 seconds.\n",
      "[2021-02-23 20:21:54,867] [TfPoseEstimator] [INFO] inference image in 0.6306 seconds.\n",
      "[2021-02-23 20:21:54,976] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:54,976] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [1.15131550e-105 1.70192394e-058 5.00000000e-001 1.71311434e-034\n",
      " 1.86354632e-030 4.99999915e-001 8.51060419e-008 1.22553443e-035\n",
      " 3.46811982e-039]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : \n",
      "dict_id2label\n",
      "{20: '', 26: '', 27: '', 28: '', 29: ''}\n",
      "\n",
      "Processing 14th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:55,613] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:55,613] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:55,627] [TfPoseEstimator] [DEBUG] estimate time=0.01297\n",
      "[2021-02-23 20:21:55,627] [TfPoseEstimator] [DEBUG] estimate time=0.01297\n",
      "[2021-02-23 20:21:55,636] [TfPoseEstimator] [INFO] inference image in 0.6593 seconds.\n",
      "[2021-02-23 20:21:55,636] [TfPoseEstimator] [INFO] inference image in 0.6593 seconds.\n",
      "[2021-02-23 20:21:55,758] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-02-23 20:21:55,758] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [8.94189162e-145 3.18561806e-047 1.78411550e-016 8.01276658e-046\n",
      " 1.86354631e-030 4.99999915e-001 5.00000085e-001 1.22553459e-035\n",
      " 3.53018445e-055]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : kick\n",
      "dict_id2label\n",
      "{20: 'kick', 28: '', 29: '', 30: '', 31: ''}\n",
      "\n",
      "Processing 15th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-23 20:21:56,379] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:56,379] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-02-23 20:21:56,396] [TfPoseEstimator] [DEBUG] estimate time=0.01539\n",
      "[2021-02-23 20:21:56,396] [TfPoseEstimator] [DEBUG] estimate time=0.01539\n",
      "[2021-02-23 20:21:56,401] [TfPoseEstimator] [INFO] inference image in 0.6429 seconds.\n",
      "[2021-02-23 20:21:56,401] [TfPoseEstimator] [INFO] inference image in 0.6429 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "\n",
      "Mean score:\n",
      " [1.09943532e-155 3.18561806e-047 3.12056598e-024 8.42972825e-032\n",
      " 1.58196796e-075 1.42676442e-047 1.00000000e+000 1.64263919e-042\n",
      " 1.52061906e-054]\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "ProcFtr.has_neck_and_thigh(x) True\n",
      "prediced label is : kick\n",
      "dict_id2label\n",
      "{20: 'kick', 28: '', 31: '', 32: '', 33: ''}\n",
      "Program ends\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import utils.lib_images_io as lib_images_io\n",
    "import utils.lib_plot as lib_plot\n",
    "import utils.lib_commons as lib_commons\n",
    "from utils.lib_openpose import SkeletonDetector\n",
    "from utils.lib_tracker import Tracker\n",
    "from utils.lib_tracker import Tracker\n",
    "from utils.lib_classifier import ClassifierOnlineTest\n",
    "from utils.lib_classifier import *  # Import all sklearn related libraries\n",
    "\n",
    "\n",
    "\n",
    "# -- Command-line input\n",
    "\n",
    "\n",
    "SRC_DATA_TYPE = \"video\"\n",
    "SRC_DATA_PATH = \"../cam1.mp4\"\n",
    "SRC_MODEL_PATH = \"models/trained_classifier.pickle\"\n",
    "\n",
    "# DST_FOLDER_NAME = get_dst_folder_name(SRC_DATA_TYPE, SRC_DATA_PATH)\n",
    "\n",
    "# -- Settings\n",
    "\n",
    "cfg_all = lib_commons.read_yaml(ROOT + \"config/config.yaml\")\n",
    "cfg = cfg_all[\"s5_test.py\"]\n",
    "\n",
    "CLASSES = np.array(cfg_all[\"classes\"])\n",
    "SKELETON_FILENAME_FORMAT = cfg_all[\"skeleton_filename_format\"]\n",
    "\n",
    "# Action recognition: number of frames used to extract features.\n",
    "WINDOW_SIZE = int(cfg_all[\"features\"][\"window_size\"])\n",
    "\n",
    "\n",
    "# Video setttings\n",
    "\n",
    "# If data_type is webcam, set the max frame rate.\n",
    "SRC_WEBCAM_MAX_FPS = float(cfg[\"settings\"][\"source\"]\n",
    "                           [\"webcam_max_framerate\"])\n",
    "\n",
    "# If data_type is video, set the sampling interval.\n",
    "# For example, if it's 3, then the video will be read 3 times faster.\n",
    "SRC_VIDEO_SAMPLE_INTERVAL = int(cfg[\"settings\"][\"source\"]\n",
    "                                [\"video_sample_interval\"])\n",
    "\n",
    "# Openpose settings\n",
    "OPENPOSE_MODEL = cfg[\"settings\"][\"openpose\"][\"model\"]\n",
    "OPENPOSE_IMG_SIZE = cfg[\"settings\"][\"openpose\"][\"img_size\"]\n",
    "\n",
    "# Display settings\n",
    "img_disp_desired_rows = int(cfg[\"settings\"][\"display\"][\"desired_rows\"])\n",
    "\n",
    "\n",
    "# -- Function\n",
    "\n",
    "\n",
    "def select_images_loader(src_data_type, src_data_path):\n",
    "    if src_data_type == \"video\":\n",
    "        images_loader = lib_images_io.ReadFromVideo(\n",
    "            src_data_path,\n",
    "            sample_interval=SRC_VIDEO_SAMPLE_INTERVAL)\n",
    "\n",
    "    elif src_data_type == \"folder\":\n",
    "        images_loader = lib_images_io.ReadFromFolder(\n",
    "            folder_path=src_data_path)\n",
    "\n",
    "    elif src_data_type == \"webcam\":\n",
    "        if src_data_path == \"\":\n",
    "            webcam_idx = 0\n",
    "        elif src_data_path.isdigit():\n",
    "            webcam_idx = int(src_data_path)\n",
    "        else:\n",
    "            webcam_idx = src_data_path\n",
    "        images_loader = lib_images_io.ReadFromWebcam(\n",
    "            SRC_WEBCAM_MAX_FPS, webcam_idx)\n",
    "    return images_loader\n",
    "\n",
    "\n",
    "class MultiPersonClassifier(object):\n",
    "    ''' This is a wrapper around ClassifierOnlineTest\n",
    "        for recognizing actions of multiple people.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_path, classes):\n",
    "\n",
    "        self.dict_id2clf = {}  # human id -> classifier of this person\n",
    "\n",
    "        # Define a function for creating classifier for new people.\n",
    "        self._create_classifier = lambda human_id: ClassifierOnlineTest(\n",
    "            model_path, classes, WINDOW_SIZE, human_id)\n",
    "\n",
    "    def classify(self, dict_id2skeleton):\n",
    "        ''' Classify the action type of each skeleton in dict_id2skeleton '''\n",
    "\n",
    "        # Clear people not in view\n",
    "        old_ids = set(self.dict_id2clf)\n",
    "        cur_ids = set(dict_id2skeleton)\n",
    "        humans_not_in_view = list(old_ids - cur_ids)\n",
    "        for human in humans_not_in_view:\n",
    "            del self.dict_id2clf[human]\n",
    "\n",
    "        # Predict each person's action\n",
    "        id2label = {}\n",
    "        for id, skeleton in dict_id2skeleton.items():\n",
    "\n",
    "            if id not in self.dict_id2clf:  # add this new person\n",
    "                self.dict_id2clf[id] = self._create_classifier(id)\n",
    "\n",
    "            classifier = self.dict_id2clf[id]\n",
    "            id2label[id] = classifier.predict(skeleton)  # predict label\n",
    "            # print(\"\\n\\nPredicting label for human{}\".format(id))\n",
    "            # print(\"  skeleton: {}\".format(skeleton))\n",
    "            # print(\"  label: {}\".format(id2label[id]))\n",
    "\n",
    "        return id2label\n",
    "\n",
    "    def get_classifier(self, id):\n",
    "        ''' Get the classifier based on the person id.\n",
    "        Arguments:\n",
    "            id {int or \"min\"}\n",
    "        '''\n",
    "        if len(self.dict_id2clf) == 0:\n",
    "            return None\n",
    "        if id == 'min':\n",
    "            id = min(self.dict_id2clf.keys())\n",
    "        return self.dict_id2clf[id]\n",
    "\n",
    "\n",
    "def remove_skeletons_with_few_joints(skeletons):\n",
    "    ''' Remove bad skeletons before sending to the tracker '''\n",
    "    good_skeletons = []\n",
    "    for skeleton in skeletons:\n",
    "        px = skeleton[2:2+13*2:2]\n",
    "        py = skeleton[3:2+13*2:2]\n",
    "        num_valid_joints = len([x for x in px if x != 0])\n",
    "        num_leg_joints = len([x for x in px[-6:] if x != 0])\n",
    "        total_size = max(py) - min(py)\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # IF JOINTS ARE MISSING, TRY CHANGING THESE VALUES:\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        if num_valid_joints >= 5 and total_size >= 0.1 and num_leg_joints >= 0:\n",
    "            # add this skeleton only when all requirements are satisfied\n",
    "            good_skeletons.append(skeleton)\n",
    "    return good_skeletons\n",
    "\n",
    "\n",
    "def draw_result_img(img_disp, ith_img, humans, dict_id2skeleton,\n",
    "                    skeleton_detector, multiperson_classifier):\n",
    "    ''' Draw skeletons, labels, and prediction scores onto image for display '''\n",
    "    \n",
    "    # Resize to a proper size for display\n",
    "    r, c = img_disp.shape[0:2]\n",
    "    desired_cols = int(1.0 * c * (img_disp_desired_rows / r))\n",
    "    img_disp = cv2.resize(img_disp,\n",
    "                          dsize=(1000, 600))\n",
    "\n",
    "    # Draw all people's skeleton\n",
    "    skeleton_detector.draw(img_disp, humans)\n",
    "\n",
    "    # Draw bounding box and label of each person\n",
    "    if len(dict_id2skeleton):\n",
    "        for id, label in dict_id2label.items():\n",
    "            skeleton = dict_id2skeleton[id]\n",
    "            # scale the y data back to original\n",
    "            skeleton[1::2] = skeleton[1::2] / scale_h\n",
    "            # print(\"Drawing skeleton: \", dict_id2skeleton[id], \"with label:\", label, \".\")\n",
    "            \n",
    "#             if(label == ''):\n",
    "#                 if id in dictId_label:\n",
    "#                     label = dictId_label[id]\n",
    "#                     dict_id2label[id] = label\n",
    "                \n",
    "            lib_plot.draw_action_result(img_disp, id, skeleton, label)\n",
    "\n",
    "    # Add blank to the left for displaying prediction scores of each class\n",
    "    img_disp = lib_plot.add_white_region_to_left_of_image(img_disp)\n",
    "\n",
    "    cv2.putText(img_disp, \"Frame:\" + str(ith_img),\n",
    "                (20, 20), fontScale=1.5, fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "                color=(0, 0, 0), thickness=2)\n",
    "\n",
    "    # Draw predicting score for only 1 person\n",
    "    if len(dict_id2skeleton):\n",
    "        classifier_of_a_person = multiperson_classifier.get_classifier(\n",
    "            id='min')\n",
    "        classifier_of_a_person.draw_scores_onto_image(img_disp)\n",
    "    return img_disp\n",
    "\n",
    "\n",
    "# -- Detector, tracker, classifier\n",
    "\n",
    "skeleton_detector = SkeletonDetector(OPENPOSE_MODEL, OPENPOSE_IMG_SIZE)\n",
    "\n",
    "multiperson_tracker = Tracker()\n",
    "\n",
    "multiperson_classifier = MultiPersonClassifier(SRC_MODEL_PATH, CLASSES)\n",
    "\n",
    "# -- Image reader and displayer\n",
    "images_loader = select_images_loader(SRC_DATA_TYPE, SRC_DATA_PATH)\n",
    "img_displayer = lib_images_io.ImageDisplayer()\n",
    "\n",
    "dictid_label = {}\n",
    "\n",
    "# -- Init output\n",
    "\n",
    "# -- Read images and process\n",
    "try:\n",
    "    ith_img = -1\n",
    "    while images_loader.has_image():\n",
    "\n",
    "        # -- Read image\n",
    "        img = images_loader.read_image()\n",
    "        ith_img += 1\n",
    "        img_disp = img.copy()\n",
    "        print(f\"\\nProcessing {ith_img}th image ...\")\n",
    "\n",
    "        # -- Detect skeletons\n",
    "        humans = skeleton_detector.detect(img)\n",
    "        skeletons, scale_h = skeleton_detector.humans_to_skels_list(humans)\n",
    "        skeletons = remove_skeletons_with_few_joints(skeletons)\n",
    "\n",
    "        \n",
    "        # -- Track people\n",
    "        dict_id2skeleton = multiperson_tracker.track(\n",
    "            skeletons)  # int id -> np.array() skeleton\n",
    "        \n",
    "\n",
    "        # -- Recognize action of each person\n",
    "        if len(dict_id2skeleton):\n",
    "            dict_id2label = multiperson_classifier.classify(\n",
    "                dict_id2skeleton)\n",
    "\n",
    "        # -- Draw\n",
    "        img_disp = draw_result_img(img_disp, ith_img, humans, dict_id2skeleton,\n",
    "                                   skeleton_detector, multiperson_classifier)\n",
    "\n",
    "        # Print label of a person\n",
    "        if len(dict_id2skeleton):\n",
    "            min_id = min(dict_id2skeleton.keys())\n",
    "            print(\"prediced label is :\", dict_id2label[min_id])\n",
    "            print(\"dict_id2label\")\n",
    "            print(dict_id2label)\n",
    "            dictId_label = dict_id2label\n",
    "\n",
    "        # -- Display image, and write to video.avi\n",
    "        img_displayer.display(img_disp, wait_key_ms=1)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Program ends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-thunder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
